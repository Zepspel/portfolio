---
title: "Lab7 desision trees"
author: "Шацких П.О."
date: "2025-11-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(rpart)
library(rpart.plot)

dframe <- read.csv("https://hyper.mephi.ru/assets/courseware/v1/345e8b1c6ea11120575066ec4ac58f4a/asset-v1:MEPhIx+CS712DS+2025Fall+type@asset+block/survey.csv")

dframe$MYDEPV <- factor(dframe$MYDEPV)

summary(dframe)
head(dframe)

df_train <- dframe[1:600,]
df_test <- dframe[601:750,]
```

## a. Build a classification tree from the training data using the “rpart” package, according to the formula “MYDEPV ~ Price + Income + Age”.  Use three-fold cross-validation and the information gain splitting index.  Which features were actually used to construct the tree?  (see the “printcp” function)  Plot the tree using the “rpart.plot” package.

3-х кратная перекрестная проверка для обрезки дерева  

Данные делятся на 3 случайные части  
Модель тренируется на 2 частях, валидируется на 1  
Процесс повторяется 3 раза (каждая часть используется для валидации)  
Усредняются ошибки  

Показывает в таблице printcp где оптимальная точка обрезки  
```{r}
model <- rpart(MYDEPV ~ Price + Income + Age, data = df_train,
               method = "class",
               parms = list(split = "information"),  # Information gain
               control = rpart.control(xval = 3))    # 3-fold cross-validation

rpart.plot(model)

printcp(model)

```

CP = (улучшение индекса Джини/энтропии) / (индекс корневого узла) 

rel_error = Ошибка_текущего_дерева / Ошибка_корневого_дерева  

Левая ветвь: [A,A,B] → ошибка = 1/3 = 0.333  
Правая ветвь: [A,B,B,B,B] → ошибка = 1/5 = 0.2
Общая ошибка = (3/8) * 0.333 + (5.8) * 1.5 


## b. Score the model with the training data and create the model’s confusion matrix.  Which class of MYDEPV was the model better able to classify?
```{r}
probabilities <- predict(model, type = "class")


conf_matrix <- table(Actual = df_train$MYDEPV, Predicted = probabilities)
print(conf_matrix)


FN0 <- conf_matrix[1,2]
TP0 <- conf_matrix[1,1]

mis_rate0 <- FN0/(FN0 + TP0)
print(mis_rate0)


FN1 <- conf_matrix[2,1]
TP1 <- conf_matrix[2,2]

mis_rate <- FN1/(FN1 + TP1)
print(mis_rate)
```

## Define the resubstitution error rate, and then calculate it using the confusion matrix from the previous step.  Is it a good indicator of predictive performance?  Why or why not?

Resubstitution Error Rate (Ошибка повторной подстановки)  
вычисляется на тех же данных, на которых модель обучалась  
```{r}
resubstitution_error <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
print(resubstitution_error)
```

```{r}
probabilities <- predict(model, df_test, type = "class")


conf_matrix <- table(Actual = df_test$MYDEPV, Predicted = probabilities)
print(conf_matrix)


FN0 <- conf_matrix[1,2]
TP0 <- conf_matrix[1,1]

mis_rate0 <- FN0/(FN0 + TP0)
print(mis_rate0)


FN1 <- conf_matrix[2,1]
TP1 <- conf_matrix[2,2]

mis_rate <- FN1/(FN1 + TP1)
print(mis_rate)
```


```{r}
resubstitution_error <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
print(resubstitution_error)
```




## Using the “ROCR” package, plot the receiver operating characteristic (ROC) curve.  Note: For a refresher on how to use the ROCR package, see Lab Exercise 7: Logistic Regression.  Calculate the area under the ROC curve (AUC).  Describe the usefulness of this statistic.


TPR = TP / TP + FN  
TPR также известен как Recall, и определяется как доля правильно классифицированных положительных результатов относительно всех положительных результатов в данных:

FPR = FP / FP + TN  
FPR определяет долю ошибочно классифицированных отрицательных результатов относительно всех отрицательных результатов  

auc value is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one.

```{r}
library(ROCR)

probabilities <- predict(model, type = "prob")[,2]

# Создаем объект prediction для ROCR
pred <- prediction(probabilities, df_train$MYDEPV)

# Создаем объект performance для ROC-кривой
perf <- performance(pred, "tpr", "fpr")

# Строим ROC-кривую
plot(perf, 
     main = "ROC Curve",
     colorize = TRUE)
     

     #print.cutoffs.at = seq(0, 1, 0.1),
     #text.adj = c(-0.2, 1.7))


abline(a = 0, b = 1, lty = 2, col = "red")

# Рассчитываем AUC (Area Under Curve)
auc <- performance(pred, "auc")
auc_value <- auc@y.values[[1]]

# Добавляем AUC на график
legend("bottomright", legend = paste("AUC =", round(auc_value, 3)), 
       bty = "n", cex = 1.2)

print(auc_value)
```

## Интерпретация результатов AUC:
AUC = 0.5 - бесполезный классификатор (как случайное угадывание)

AUC = 0.7-0.8 - хороший классификатор

AUC = 0.8-0.9 - очень хороший классификатор

AUC > 0.9 - отличный классификатор


## e. Score the model with the testing data.  How accurate are the tree’s predictions?
```{r}
prob <- predict(model, df_test, type = "class")

conf_matrix <- table(Actual = df_test$MYDEPV, Predicted = prob)
print(conf_matrix)

FN0 <- conf_matrix[1,2]
TP0 <- conf_matrix[1,1]

mis_rate0 <- FN0/(FN0 + TP0)
print(mis_rate0)


FN1 <- conf_matrix[2,1]
TP1 <- conf_matrix[2,2]

mis_rate <- FN1/(FN1 + TP1)
print(mis_rate)
```


## f.        Repeat part (a), but set the splitting index to the Gini coefficient splitting index.  How does the new tree compare to the previous one? 
```{r}
model <- rpart(MYDEPV ~ Price + Income + Age, data = df_train,
               method = "class",
               parms = list(split = "gini"),  # Information gain
               control = rpart.control(xval = 3))    # 3-fold cross-validation

rpart.plot(model)

printcp(model)
```

```{r}
probabilities <- predict(model, type = "class")


conf_matrix <- table(Actual = df_train$MYDEPV, Predicted = probabilities)
print(conf_matrix)


FN0 <- conf_matrix[1,2]
TP0 <- conf_matrix[1,1]

mis_rate0 <- FN0/(FN0 + TP0)
print(mis_rate0)


FN1 <- conf_matrix[2,1]
TP1 <- conf_matrix[2,2]

mis_rate <- FN1/(FN1 + TP1)
print(mis_rate)
```


```{r}
resubstitution_error <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
print(resubstitution_error)
```


```{r}
probabilities <- predict(model, type = "prob")[,2]

# Создаем объект prediction для ROCR
pred <- prediction(probabilities, df_train$MYDEPV)

# Создаем объект performance для ROC-кривой
perf <- performance(pred, "tpr", "fpr")

# Строим ROC-кривую
plot(perf, 
     main = "ROC Curve",
     colorize = TRUE)



abline(a = 0, b = 1, lty = 2, col = "red")

# Рассчитываем AUC (Area Under Curve)
auc <- performance(pred, "auc")
auc_value <- auc@y.values[[1]]

# Добавляем AUC на график
legend("bottomright", legend = paste("AUC =", round(auc_value, 3)), 
       bty = "n", cex = 1.2)

print(auc_value)
```






## g. Pruning is a technique that reduces the size/depth of a decision tree by removing sections with low classification power, which helps reduce overfitting and simplifies the model, reducing the computational cost.  One way to prune a tree is according to the complexity parameter associated with the smallest cross-validation error.  Prune the new tree in this way using the “prune” function.  Which features were actually used in the pruned tree?  Why were certain variables not used?
```{r}
model = prune(model, cp = 0.0115380)

rpart.plot(model)


printcp(model)
```

```{r}
probabilities <- predict(model, df_test, type = "class")


conf_matrix <- table(Actual = df_test$MYDEPV, Predicted = probabilities)
print(conf_matrix)


FN0 <- conf_matrix[1,2]
TP0 <- conf_matrix[1,1]

mis_rate0 <- FN0/(FN0 + TP0)
print(mis_rate0)


FN1 <- conf_matrix[2,1]
TP1 <- conf_matrix[2,2]

mis_rate <- FN1/(FN1 + TP1)
print(mis_rate)
```


```{r}
resubstitution_error <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
print(resubstitution_error)
```



```{r}
probabilities <- predict(model, type = "class")


conf_matrix <- table(Actual = df_train$MYDEPV, Predicted = probabilities)
print(conf_matrix)


FN0 <- conf_matrix[1,2]
TP0 <- conf_matrix[1,1]

mis_rate0 <- FN0/(FN0 + TP0)
print(mis_rate0)


FN1 <- conf_matrix[2,1]
TP1 <- conf_matrix[2,2]

mis_rate <- FN1/(FN1 + TP1)
print(mis_rate)
```


```{r}
resubstitution_error <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
print(resubstitution_error)
```


